{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69564f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "from typing import List, Dict, Any\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53aa77fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RedditDataExtractor:\n",
    "    def __init__(self, client_id, client_secret, user_agent):\n",
    "        self.reddit = praw.Reddit(\n",
    "            client_id=client_id,\n",
    "            client_secret=client_secret,\n",
    "            user_agent=user_agent\n",
    "        )\n",
    "    \n",
    "    def get_posts_with_comments(self, subreddit_name: str, limit: int = 100, \n",
    "                              posts_delay: float = 2.0, comments_delay: float = 1.0):\n",
    "        print(f\"Starting extraction from r/{subreddit_name}...\")\n",
    "        \n",
    "        all_data = []\n",
    "        subreddit = self.reddit.subreddit(subreddit_name)\n",
    "        \n",
    "        try:\n",
    "            for i, post in enumerate(subreddit.hot(limit=limit)):\n",
    "                try:\n",
    "                    print(f\"Processing post {i+1}/{limit}: {post.title[:50]}...\")\n",
    "                    \n",
    "                    # Extract post data\n",
    "                    post_data = self._extract_post_data(post)\n",
    "                    all_data.append(post_data)\n",
    "                    \n",
    "                    # Extract comments as nested structure\n",
    "                    comments_tree = self._extract_comments_hierarchy(post, comments_delay)\n",
    "                    all_data.extend(comments_tree)\n",
    "                    \n",
    "                    if i < limit - 1:\n",
    "                        time.sleep(posts_delay)\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing post {i+1}: {str(e)}\")\n",
    "                    continue\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error accessing subreddit: {str(e)}\")\n",
    "            return []\n",
    "            \n",
    "        return all_data\n",
    "    \n",
    "    def _extract_post_data(self, post) -> Dict[str, Any]:\n",
    "        return {\n",
    "            'post_id': post.id,\n",
    "            'comment_id': post.id,\n",
    "            'parent_id': None,\n",
    "            'level': 0,\n",
    "            'level_path': '0',\n",
    "            'type': 'post',\n",
    "            'title': post.title,\n",
    "            'body': self._clean_text(post.selftext),\n",
    "            'author': str(post.author) if post.author else '[deleted]',\n",
    "            'score': post.score,\n",
    "            'upvote_ratio': post.upvote_ratio,\n",
    "            'num_comments': post.num_comments,\n",
    "            'created_utc': datetime.datetime.fromtimestamp(post.created_utc),\n",
    "            'url': post.url,\n",
    "            'permalink': post.permalink,\n",
    "            'is_original_content': post.is_original_content,\n",
    "            'is_self': post.is_self,\n",
    "            'over_18': post.over_18,\n",
    "            'spoiler': post.spoiler,\n",
    "            'stickied': post.stickied\n",
    "        }\n",
    "    \n",
    "    def _extract_comments_hierarchy(self, post, comments_delay: float) -> List[Dict[str, Any]]:\n",
    "        comments_data = []\n",
    "        \n",
    "        try:\n",
    "            post.comments.replace_more(limit=None)\n",
    "            \n",
    "            for i, comment in enumerate(post.comments):\n",
    "                comment_path = f\"0.{i}\"\n",
    "                self._process_comment_hierarchy(comment, comments_data, level=1, \n",
    "                                              parent_id=post.id, \n",
    "                                              level_path=comment_path,\n",
    "                                              delay=comments_delay)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting comments for post {post.id}: {str(e)}\")\n",
    "            \n",
    "        return comments_data\n",
    "    \n",
    "    def _process_comment_hierarchy(self, comment, comments_data: List, level: int, \n",
    "                                parent_id: str, level_path: str, delay: float):\n",
    "        try:\n",
    "            comment_data = {\n",
    "                'post_id': getattr(comment, 'submission', None) and comment.submission.id or 'unknown',\n",
    "                'comment_id': comment.id,\n",
    "                'parent_id': parent_id,\n",
    "                'level': level,\n",
    "                'level_path': level_path,\n",
    "                'type': 'comment',\n",
    "                'title': '',\n",
    "                'body': self._clean_text(comment.body),\n",
    "                'author': str(comment.author) if comment.author else '[deleted]',\n",
    "                'score': comment.score,\n",
    "                'upvote_ratio': None,\n",
    "                'num_comments': len(comment.replies) if hasattr(comment, 'replies') else 0,\n",
    "                'created_utc': datetime.datetime.fromtimestamp(comment.created_utc),\n",
    "                'url': f\"https://reddit.com{comment.permalink}\",\n",
    "                'permalink': comment.permalink,\n",
    "                'is_original_content': None,\n",
    "                'is_self': None,\n",
    "                'over_18': getattr(comment, 'over_18', False),\n",
    "                'spoiler': getattr(comment, 'spoiler', False),\n",
    "                'stickied': comment.stickied\n",
    "            }\n",
    "            \n",
    "            comments_data.append(comment_data)\n",
    "            \n",
    "            time.sleep(delay)\n",
    "            \n",
    "            # Process replies with hierarchical numbering\n",
    "            if hasattr(comment, 'replies'):\n",
    "                for j, reply in enumerate(comment.replies):\n",
    "                    reply_path = f\"{level_path}.{j}\"\n",
    "                    self._process_comment_hierarchy(reply, comments_data, level + 1, \n",
    "                                                  parent_id=comment.id, \n",
    "                                                  level_path=reply_path,\n",
    "                                                  delay=delay)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing comment {comment.id}: {str(e)}\")\n",
    "    \n",
    "    def _clean_text(self, text: str) -> str:\n",
    "        \"\"\"Clean text for CSV/Excel\"\"\"\n",
    "        if not text:\n",
    "            return \"\"\n",
    "        # Remove excessive newlines and clean text\n",
    "        text = ' '.join(text.split())\n",
    "        return text[:10000]  # Limit very long texts\n",
    "    \n",
    "    def save_to_excel_with_hierarchy(self, data: List[Dict[str, Any]], filename: str):\n",
    "        \"\"\"Save with hierarchical structure clearly visible\"\"\"\n",
    "        if not data:\n",
    "            print(\"No data to save!\")\n",
    "            return\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # Create a display column that shows the hierarchy\n",
    "        def create_display_row(row):\n",
    "            indent = \"  \" * row['level']\n",
    "            if row['type'] == 'post':\n",
    "                return f\"üìù POST: {row['title']}\"\n",
    "            else:\n",
    "                author = row['author'] if row['author'] != '[deleted]' else 'deleted'\n",
    "                return f\"{indent}üí¨ [{row['level_path']}] {author}: {row['body'][:100]}...\"\n",
    "        \n",
    "        df['display_hierarchy'] = df.apply(create_display_row, axis=1)\n",
    "        \n",
    "        # Reorder columns for better readability\n",
    "        columns_order = [\n",
    "            'display_hierarchy', 'level_path', 'level', 'type', 'post_id', 'comment_id', 'parent_id',\n",
    "            'title', 'body', 'author', 'score', 'created_utc', 'num_comments',\n",
    "            'upvote_ratio', 'url', 'permalink', 'is_original_content', 'is_self',\n",
    "            'over_18', 'spoiler', 'stickied'\n",
    "        ]\n",
    "        \n",
    "        # Only include existing columns\n",
    "        existing_columns = [col for col in columns_order if col in df.columns]\n",
    "        df = df[existing_columns]\n",
    "        \n",
    "        try:\n",
    "            with pd.ExcelWriter(filename, engine='openpyxl') as writer:\n",
    "                df.to_excel(writer, sheet_name='Reddit Data', index=False)\n",
    "                \n",
    "                worksheet = writer.sheets['Reddit Data']\n",
    "                \n",
    "                # Adjust column widths\n",
    "                for column in worksheet.columns:\n",
    "                    max_length = 0\n",
    "                    column_letter = column[0].column_letter\n",
    "                    for cell in column:\n",
    "                        try:\n",
    "                            if len(str(cell.value)) > max_length:\n",
    "                                max_length = len(str(cell.value))\n",
    "                        except:\n",
    "                            pass\n",
    "                    adjusted_width = min(max_length + 2, 50)\n",
    "                    worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "            \n",
    "            print(f\"‚úÖ Hierarchical data saved to {filename}\")\n",
    "            \n",
    "        except ImportError:\n",
    "            print(\"‚ùå openpyxl not installed. Saving as CSV instead.\")\n",
    "            self.save_to_csv_with_hierarchy(data, filename.replace('.xlsx', '.csv'))\n",
    "    \n",
    "    def save_to_csv_with_hierarchy(self, data: List[Dict[str, Any]], filename: str):\n",
    "        \"\"\"Save hierarchical data to CSV\"\"\"\n",
    "        if not data:\n",
    "            print(\"No data to save!\")\n",
    "            return\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # Add display hierarchy column\n",
    "        def create_display_row(row):\n",
    "            indent = \"  \" * row['level']\n",
    "            if row['type'] == 'post':\n",
    "                return f\"POST: {row['title']}\"\n",
    "            else:\n",
    "                author = row['author'] if row['author'] != '[deleted]' else 'deleted'\n",
    "                return f\"{indent}[{row['level_path']}] {author}: {row['body'][:100]}...\"\n",
    "        \n",
    "        df['display_hierarchy'] = df.apply(create_display_row, axis=1)\n",
    "        \n",
    "        # Reorder to put hierarchy first\n",
    "        cols = df.columns.tolist()\n",
    "        cols.remove('display_hierarchy')\n",
    "        cols = ['display_hierarchy'] + cols\n",
    "        df = df[cols]\n",
    "        \n",
    "        df.to_csv(filename, index=False, encoding='utf-8')\n",
    "        print(f\"‚úÖ Hierarchical data saved to {filename}\")\n",
    "    \n",
    "    def print_hierarchy_preview(self, data: List[Dict[str, Any]], max_rows: int = 20):\n",
    "        \"\"\"Print a preview of the hierarchical structure\"\"\"\n",
    "        if not data:\n",
    "            print(\"No data to display!\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"HIERARCHICAL PREVIEW (Tree Structure)\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        for i, item in enumerate(data[:max_rows]):\n",
    "            indent = \"  \" * item['level']\n",
    "            if item['type'] == 'post':\n",
    "                print(f\"{indent}üìù POST: {item['title']}\")\n",
    "                print(f\"{indent}     By: {item['author']} | Score: {item['score']} | Comments: {item['num_comments']}\")\n",
    "            else:\n",
    "                print(f\"{indent}üí¨ [{item['level_path']}] {item['author']}: {item['body'][:100]}...\")\n",
    "            \n",
    "            if i < max_rows - 1:\n",
    "                level_current = item['level']\n",
    "                level_next = data[i+1]['level'] if i+1 < len(data) else 0\n",
    "                if level_next < level_current:\n",
    "                    print()  # Add space when going up levels\n",
    "        \n",
    "        if len(data) > max_rows:\n",
    "            print(f\"\\n... and {len(data) - max_rows} more rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be766ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your credentials\n",
    "extractor = RedditDataExtractor(\n",
    "    client_id=\"\",         # your client id\n",
    "    client_secret=\"\",      # your client secret\n",
    "    user_agent=\"\" #user agent name\n",
    ")\n",
    "\n",
    "# Extract data\n",
    "data = extractor.get_posts_with_comments(\n",
    "    subreddit_name=\"\",  #subreddit\n",
    "    limit=400,  # how many post\n",
    "    posts_delay=2.0, #post delay\n",
    "    comments_delay=1.0 # comment delay\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee5572ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved 761 records to reddit_data.csv\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(data).to_csv(\"pharil2.csv\", index=False)\n",
    "print(f\"‚úÖ Saved {len(data)} records to reddit_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a50477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
